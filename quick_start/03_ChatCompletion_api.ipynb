{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Basic Usage of the Azure OpenAI SDK\n",
                "Learn how to use the gpt model through the ChatCompletion API.  \n",
                "The prompts are composed of both English and Korean. Try conducting cross-language tests."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from openai import AzureOpenAI\n",
                "from dotenv import load_dotenv\n",
                "load_dotenv()\n",
                "\n",
                "client = AzureOpenAI(\n",
                "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\",\"\").strip(),\n",
                "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
                "    api_version    = os.getenv(\"OPENAI_API_VERSION\")\n",
                ")\n",
                "\n",
                "deployment_name    = os.getenv('DEPLOYMENT_NAME')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Sorry, I don't know.\n"
                    ]
                }
            ],
            "source": [
                "system_msg = \"\"\"Answer the question as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\".\"\"\"\n",
                "user_msg = \"\"\"Q: Who is the winner of the men's marathon at the 2024 Paris Olympics? A:\"\"\"\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=deployment_name,\n",
                "    messages=[\n",
                "        {\"role\": \"system\", \"content\": system_msg},\n",
                "        {\"role\": \"user\", \"content\": user_msg},\n",
                "    ],\n",
                "    temperature=0,\n",
                "    max_tokens=1000\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Distinguishing between Positive and Negative Feedback"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Q1: Negative  \n",
                        "Q2: Positive  \n"
                    ]
                }
            ],
            "source": [
                "system_msg = \"\"\"Determine if each piece of feedback provided below is positive or negative.\"\"\"\n",
                "user_msg = \"\"\"Q1: I was disappointed with the quality of the product. It was very cheaply made and did not meet my expectations at all.\n",
                "Q2: I was satisfied with this product. Itâ€™s well-made and offers good value for the price.\"\"\"\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=deployment_name,\n",
                "    messages=[\n",
                "        {\"role\": \"system\", \"content\": system_msg},\n",
                "        {\"role\": \"user\", \"content\": user_msg},\n",
                "    ],\n",
                "    temperature=0,\n",
                "    max_tokens=1000\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Extracting Personal Data\n",
                "Check the performance of GPT-4o-mini for extracting PII data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The PII (Personally Identifiable Information) data from the statement includes:\n",
                        "\n",
                        "1. Full name: John Doe\n",
                        "2. Age: 35 years old\n",
                        "3. Address: 21 Main Street, New York, NY\n",
                        "4. Occupation: Software engineer\n",
                        "5. Employer: Microsoft\n",
                        "6. Spouse's name: Jane Doe\n",
                        "7. Number of children: Two children\n"
                    ]
                }
            ],
            "source": [
                "deployment_name = \"gpt-4o-mini\"\n",
                "\n",
                "system_msg = \"\"\"List all PII data from following statement:\"\"\"\n",
                "user_msg = \"\"\"John Doe is a 35-year old man and he lives at 21 Main Street, New York, NY. He is a software engineer and he works at Microsoft. He has a wife named Jane Doe and they have two children\"\"\"\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=deployment_name,\n",
                "    messages=[\n",
                "        {\"role\": \"system\", \"content\": system_msg},\n",
                "        {\"role\": \"user\", \"content\": user_msg},\n",
                "    ],\n",
                "    temperature=0,\n",
                "    max_tokens=1000\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Checking the performance of GPT-4o for extracting PII data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "The following are the pieces of Personally Identifiable Information (PII) from the statement:\n",
                        "\n",
                        "1. **Full Name**: John Doe  \n",
                        "2. **Age**: 35 years old  \n",
                        "3. **Address**: 21 Main Street, New York, NY  \n",
                        "4. **Occupation**: Software engineer  \n",
                        "5. **Employer**: Microsoft  \n",
                        "6. **Spouse's Name**: Jane Doe  \n",
                        "7. **Family Information**: Two children  \n",
                        "\n",
                        "Let me know if you need further clarification!\n"
                    ]
                }
            ],
            "source": [
                "deployment_name = \"gpt-4o\"\n",
                "\n",
                "system_msg = \"\"\"List all PII data from following statement:\"\"\"\n",
                "user_msg = \"\"\"John Doe is a 35-year old man and he lives at 21 Main Street, New York, NY. He is a software engineer and he works at Microsoft. He has a wife named Jane Doe and they have two children\"\"\"\n",
                "\n",
                "response = client.chat.completions.create(\n",
                "    model=deployment_name,\n",
                "    messages=[\n",
                "        {\"role\": \"system\", \"content\": system_msg},\n",
                "        {\"role\": \"user\", \"content\": user_msg},\n",
                "    ],\n",
                "    temperature=0,\n",
                "    max_tokens=1000\n",
                ")\n",
                "\n",
                "print(response.choices[0].message.content)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.4"
        },
        "orig_nbformat": 4
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
