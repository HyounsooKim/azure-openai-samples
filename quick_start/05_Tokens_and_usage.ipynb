{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding Token Structure and Usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This works correctly when gpt-35-turbo is deployed.  \n",
    "(If it is not deployed, an error may occur.)  \n",
    "An example has been added to utilize the new tokenizer for gpt-4o and gpt-4o mini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "    azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\",\"\").strip(),\n",
    "    api_key        = os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "    api_version    = os.getenv(\"OPENAI_API_VERSION\")\n",
    ")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "# deployment_name = os.getenv('DEPLOYMENT_NAME')\n",
    "deployment_name = \"gpt-35-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 9\n",
      "Tokens : [79207, 5377, 15836, 2532, 374, 3331, 16528, 1457, 0]\n",
      "Words :  ['Azure', ' Open', 'AI', ' service', ' is', ' General', ' Available', ' now', '!']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Azure OpenAI service is General Available now!\"\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Tokens :', tokens)\n",
    "print('Words : ', [encoding.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt},\n",
    "    ],\n",
    "  temperature=0.7,\n",
    "  max_tokens=60,\n",
    "  n=2\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show 2 returned results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================== ANSWER #1 ==============================\n",
      "Completion_tokens: 44\n",
      "That's great news! Azure OpenAI service being generally available means that more users can now take advantage of its features and capabilities. If you have any questions or need assistance with using the service, feel free to ask!\n",
      "============================== ANSWER #2 ==============================\n",
      "Completion_tokens: 48\n",
      "That's great news! Azure OpenAI service being generally available means that more developers can now access and utilize the service for their projects. If you have any questions or need assistance with using the Azure OpenAI service, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(response.choices)):\n",
    "    assistant_msg = (response.choices[i].message.content)\n",
    "    print('='*30, 'ANSWER #' + str(i+1), '='*30)\n",
    "    print('Completion_tokens:', len(encoding.encode(assistant_msg)))\n",
    "    print(assistant_msg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionUsage(completion_tokens=92, prompt_tokens=26, total_tokens=118)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 15\n",
      "Tokens : [31495, 230, 75265, 243, 92245, 19097, 222, 16969, 62398, 89059, 255, 33229, 39519, 234, 80052]\n",
      "Words :  ['�', '�', '�', '�', '하세요', ' �', '�', '는', ' 한', '�', '�', ' 사', '�', '�', '입니다']\n"
     ]
    }
   ],
   "source": [
    "prompt = \"안녕하세요 저는 한국 사람입니다\"\n",
    "\n",
    "tokens = encoding.encode(prompt)\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Tokens :', tokens)\n",
    "print('Words : ', [encoding.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved Tokenizer for GPT-4o & GPT-4o mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"o200k_base\")\n",
    "assert enc.decode(enc.encode(\"hello world\")) == \"hello world\"\n",
    "\n",
    "# To get the tokenizer corresponding to a specific model in the OpenAI API:\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 6\n",
      "Tokens : [14307, 171731, 199090, 52971, 34014, 27001]\n",
      "Words :  ['안', '녕하세요', ' 저는', ' 한국', ' 사람', '입니다']\n"
     ]
    }
   ],
   "source": [
    "tokens = enc.encode(prompt)\n",
    "print('Total number of tokens:', len(tokens))\n",
    "print('Tokens :', tokens)\n",
    "print('Words : ', [enc.decode([t]) for t in tokens])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that `gpt-4o` or `gpt-4o-mini` models are further optimized for the Korean language. Costs are reduced, and response times are faster.  \n",
    "You can check the tokenizer for each model at the following [link](https://platform.openai.com/tokenizer)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
